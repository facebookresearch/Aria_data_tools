"use strict";(self.webpackChunkstaticdocs_starter=self.webpackChunkstaticdocs_starter||[]).push([[913],{3905:function(e,t,r){r.r(t),r.d(t,{MDXContext:function(){return m},MDXProvider:function(){return c},mdx:function(){return g},useMDXComponents:function(){return s},withMDXComponents:function(){return p}});var a=r(67294);function n(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function i(){return(i=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var r=arguments[t];for(var a in r)Object.prototype.hasOwnProperty.call(r,a)&&(e[a]=r[a])}return e}).apply(this,arguments)}function o(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,a)}return r}function d(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?o(Object(r),!0).forEach((function(t){n(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):o(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function l(e,t){if(null==e)return{};var r,a,n=function(e,t){if(null==e)return{};var r,a,n={},i=Object.keys(e);for(a=0;a<i.length;a++)r=i[a],t.indexOf(r)>=0||(n[r]=e[r]);return n}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)r=i[a],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(n[r]=e[r])}return n}var m=a.createContext({}),p=function(e){return function(t){var r=s(t.components);return a.createElement(e,i({},t,{components:r}))}},s=function(e){var t=a.useContext(m),r=t;return e&&(r="function"==typeof e?e(t):d(d({},t),e)),r},c=function(e){var t=s(e.components);return a.createElement(m.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},x=a.forwardRef((function(e,t){var r=e.components,n=e.mdxType,i=e.originalType,o=e.parentName,m=l(e,["components","mdxType","originalType","parentName"]),p=s(r),c=n,x=p["".concat(o,".").concat(c)]||p[c]||u[c]||i;return r?a.createElement(x,d(d({ref:t},m),{},{components:r})):a.createElement(x,d({ref:t},m))}));function g(e,t){var r=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var i=r.length,o=new Array(i);o[0]=x;var d={};for(var l in t)hasOwnProperty.call(t,l)&&(d[l]=t[l]);d.originalType=e,d.mdxType="string"==typeof e?e:n,o[1]=d;for(var m=2;m<i;m++)o[m]=r[m];return a.createElement.apply(null,o)}return a.createElement.apply(null,r)}x.displayName="MDXCreateElement"},86492:function(e,t,r){r.r(t),r.d(t,{contentTitle:function(){return l},default:function(){return c},frontMatter:function(){return d},metadata:function(){return m},toc:function(){return p}});var a=r(83117),n=r(80102),i=(r(67294),r(3905)),o=["components"],d={sidebar_position:2,id:"desktop_setup",title:"Desktop Activities Capture Setup"},l="Desktop Activities Capture Setup",m={unversionedId:"pilotdata/desk/desktop_setup",id:"pilotdata/desk/desktop_setup",isDocsHomePage:!1,title:"Desktop Activities Capture Setup",description:"The Desktop Activities dataset was captured with a Project Aria device and a multi-view motion capture system.",source:"@site/docs/pilotdata/desk/desktop_setup.md",sourceDirName:"pilotdata/desk",slug:"/pilotdata/desk/desktop_setup",permalink:"/Aria_data_tools/docs/pilotdata/desk/desktop_setup",editUrl:"https://github.com/facebookresearch/aria_data_tools/docs/pilotdata/desk/desktop_setup.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2,id:"desktop_setup",title:"Desktop Activities Capture Setup"},sidebar:"tutorialSidebar",previous:{title:"Desktop Activities Overview",permalink:"/Aria_data_tools/docs/pilotdata/desk/desktop_overview"},next:{title:"How Project Aria Uses VRS",permalink:"/Aria_data_tools/docs/aria-vrs"}},p=[{value:"Hardware setup",id:"hardware-setup",children:[]},{value:"Project Aria device sensor profile",id:"project-aria-device-sensor-profile",children:[]},{value:"Trigger alignment and synchronized frames",id:"trigger-alignment-and-synchronized-frames",children:[]}],s={toc:p};function c(e){var t=e.components,r=(0,n.Z)(e,o);return(0,i.mdx)("wrapper",(0,a.Z)({},s,r,{components:t,mdxType:"MDXLayout"}),(0,i.mdx)("h1",{id:"desktop-activities-capture-setup"},"Desktop Activities Capture Setup"),(0,i.mdx)("p",null,"The Desktop Activities dataset was captured with a Project Aria device and a multi-view motion capture system."),(0,i.mdx)("h2",{id:"hardware-setup"},"Hardware setup"),(0,i.mdx)("p",null,"To record this dataset we built a system with 16 ",(0,i.mdx)("a",{parentName:"p",href:"https://optitrack.com/cameras/primex-13w/"},"OptiTrack Prime X 13 W")," motion tracking cameras and 12 ",(0,i.mdx)("a",{parentName:"p",href:"https://optitrack.com/cameras/prime-color/buy.html"},"OptiTrack Prime Color FS")," color cameras with 1080 x 1920 pixel resolution. These cameras are mounted on a desktop rig, similar to the setup used to collect the ",(0,i.mdx)("a",{parentName:"p",href:"https://assembly-101.github.io/"},"Assembly101 dataset"),"."),(0,i.mdx)("p",null,"The multi-view system is calibrated with ",(0,i.mdx)("a",{parentName:"p",href:"https://optitrack.com/software/motive/"},"OptiTrack Motive")," to obtain the intrinsics and extrinsics of all cameras. We attached markers to the Project Aria device and objects being manipulated to track their motion. We also calibrated the Project Aria device to obtain the sensor trajectories with respect to multi-view camera coordinates."),(0,i.mdx)("h2",{id:"project-aria-device-sensor-profile"},"Project Aria device sensor profile"),(0,i.mdx)("p",null,"Sensor profiles allow researchers to choose which sensors on the Project Aria device to use when collecting data."),(0,i.mdx)("p",null,"For Desktop Activities, we used Sensor Profile M, so each Project Aria device recording contains:"),(0,i.mdx)("ul",null,(0,i.mdx)("li",{parentName:"ul"},"One RGB camera stream with 1408x1408 pixel resolution"),(0,i.mdx)("li",{parentName:"ul"},"Two SLAM camera streams with 640x480 pixel resolution"),(0,i.mdx)("li",{parentName:"ul"},"One eye tracking (ET) camera stream with 320x240 pixel resolution"),(0,i.mdx)("li",{parentName:"ul"},"Two IMU sensor streams (1KHz and 800Hz)")),(0,i.mdx)("p",null,(0,i.mdx)("strong",{parentName:"p"},"Table 1:")," ",(0,i.mdx)("em",{parentName:"p"},"Sensor Profile M")),(0,i.mdx)("table",null,(0,i.mdx)("thead",{parentName:"table"},(0,i.mdx)("tr",{parentName:"thead"},(0,i.mdx)("th",{parentName:"tr",align:null},"Sensor"),(0,i.mdx)("th",{parentName:"tr",align:null},"Profile M"))),(0,i.mdx)("tbody",{parentName:"table"},(0,i.mdx)("tr",{parentName:"tbody"},(0,i.mdx)("td",{parentName:"tr",align:null},"SLAM - resolution"),(0,i.mdx)("td",{parentName:"tr",align:null},"640x480")),(0,i.mdx)("tr",{parentName:"tbody"},(0,i.mdx)("td",{parentName:"tr",align:null},"SLAM - FPS"),(0,i.mdx)("td",{parentName:"tr",align:null},"15")),(0,i.mdx)("tr",{parentName:"tbody"},(0,i.mdx)("td",{parentName:"tr",align:null},"SLAM - encoding format"),(0,i.mdx)("td",{parentName:"tr",align:null},"RAW")),(0,i.mdx)("tr",{parentName:"tbody"},(0,i.mdx)("td",{parentName:"tr",align:null},"SLAM - bits per pixel (bpp)"),(0,i.mdx)("td",{parentName:"tr",align:null},"8")),(0,i.mdx)("tr",{parentName:"tbody"},(0,i.mdx)("td",{parentName:"tr",align:null},"RGB - gain, exposure and temperature"),(0,i.mdx)("td",{parentName:"tr",align:null},"Yes")),(0,i.mdx)("tr",{parentName:"tbody"},(0,i.mdx)("td",{parentName:"tr",align:null},"ET - resolution"),(0,i.mdx)("td",{parentName:"tr",align:null},"320x240")),(0,i.mdx)("tr",{parentName:"tbody"},(0,i.mdx)("td",{parentName:"tr",align:null},"ET - FPS"),(0,i.mdx)("td",{parentName:"tr",align:null},"15")),(0,i.mdx)("tr",{parentName:"tbody"},(0,i.mdx)("td",{parentName:"tr",align:null},"ET - encoding format"),(0,i.mdx)("td",{parentName:"tr",align:null},"JPEG")),(0,i.mdx)("tr",{parentName:"tbody"},(0,i.mdx)("td",{parentName:"tr",align:null},"ET - bpp"),(0,i.mdx)("td",{parentName:"tr",align:null},"8")),(0,i.mdx)("tr",{parentName:"tbody"},(0,i.mdx)("td",{parentName:"tr",align:null},"ET - gain and exposure"),(0,i.mdx)("td",{parentName:"tr",align:null},"Yes")),(0,i.mdx)("tr",{parentName:"tbody"},(0,i.mdx)("td",{parentName:"tr",align:null},"RGB - resolution"),(0,i.mdx)("td",{parentName:"tr",align:null},"1408x1408")),(0,i.mdx)("tr",{parentName:"tbody"},(0,i.mdx)("td",{parentName:"tr",align:null},"RGB - FPS"),(0,i.mdx)("td",{parentName:"tr",align:null},"15")),(0,i.mdx)("tr",{parentName:"tbody"},(0,i.mdx)("td",{parentName:"tr",align:null},"RGB - encoding format"),(0,i.mdx)("td",{parentName:"tr",align:null},"JPEG")),(0,i.mdx)("tr",{parentName:"tbody"},(0,i.mdx)("td",{parentName:"tr",align:null},"RGB - bpp"),(0,i.mdx)("td",{parentName:"tr",align:null},"8")),(0,i.mdx)("tr",{parentName:"tbody"},(0,i.mdx)("td",{parentName:"tr",align:null},"RGB - gain, exposure and temperature"),(0,i.mdx)("td",{parentName:"tr",align:null},"Yes")),(0,i.mdx)("tr",{parentName:"tbody"},(0,i.mdx)("td",{parentName:"tr",align:null},"IMU - RIGHT acc/gyro - rate"),(0,i.mdx)("td",{parentName:"tr",align:null},"1kHz")),(0,i.mdx)("tr",{parentName:"tbody"},(0,i.mdx)("td",{parentName:"tr",align:null},"IMU - RIGHT temperature - rate"),(0,i.mdx)("td",{parentName:"tr",align:null},"~1Hz")),(0,i.mdx)("tr",{parentName:"tbody"},(0,i.mdx)("td",{parentName:"tr",align:null},"IMU - LEFT acc/gyro - rate"),(0,i.mdx)("td",{parentName:"tr",align:null},"800Hz")),(0,i.mdx)("tr",{parentName:"tbody"},(0,i.mdx)("td",{parentName:"tr",align:null},"IMU - LEFT temperature - rate"),(0,i.mdx)("td",{parentName:"tr",align:null},"~1Hz")))),(0,i.mdx)("h2",{id:"trigger-alignment-and-synchronized-frames"},"Trigger alignment and synchronized frames"),(0,i.mdx)("p",null,"During recording, the multi-view system and the Project Aria device operated at different frame rates. The Project Aria device recorded at 15FPS and with multi-view cameras recorded at 60 FPS. When recording an activity, the multi-view system and the Project Aria device started and stopped recording asynchronously.Leveraging ",(0,i.mdx)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/SMPTE_timecode"},"SMPTE timecode"),", all sensors were synchronized to a global timeline. In addition, all cameras were trigger aligned while recording."),(0,i.mdx)("p",null,"Using Sensor Profile M, the Project Aria device produced 4 synchronized camera images (1 RGB, 2 SLAM, and 1 ET image) per frame. The multi-view system produced 12 synchronized RGB camera images per frame."),(0,i.mdx)("p",null,"During the overlapping capture time, the camera trigger alignment let us accurately associate frames from the Project Aria device to frames from the multi-view system. With 15 FPS for the Project Aria device and 60 FPS for the multi-view system, 1 out of every 4 multi-view frames was trigger aligned to one Project Aria device frame."))}c.isMDXComponent=!0}}]);